permissions:
  contents: write

name: Fetch FlowScan builder‑fills archive

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # daily at midnight UTC

jobs:
  fetch:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - builder: pvp_dot_trade
            addr: '0x0cbf655b0d22ae71fba3a674b0e1c0c7e7f975af'
            start: '2024-10-27'
          - builder: liquid_perps
            addr: '0x6d4e7f472e6a491b98cbeed327417e310ae8ce48'
            start: '2025-06-15'
          - builder: pocket_pro
            addr: '0x7151A036313EEe8Aa9Bc45d0969ca0E1637AAd3C'
            start: '2025-06-20'
          - builder: phantom
            addr: '0xb84168cf3be63c6b8dad05ff5d755e97432ff80b'
            start: '2025-06-12'
          - builder: okto
            addr: '0x05984fd37db96dc2a11a09519a8def556e80590b'
            start: '2024-11-04'
          - builder: axiom
            addr: '0x1cc34f6af34653c515b47a83e1de70ba9b0cda1f'
            start: '2025-01-20'
          - builder: insilico
            addr: '0x2868fc0d9786a740b491577a43502259efa78a39'
            start: '2024-11-24'
          - builder: kinto
            addr: '0xc1f4d15c16a1f3555e0a5f7aefd1e17ad4aaf40b'
            start: '2024-12-25'
          - builder: dextrabot
            addr: '0x49ae63056b3a0be0b166813ee687309ab653c07c'
            start: '2025-02-16'
          - builder: hyperdash
            addr: '0xe966a12bf7b93838096e4519a684519ab22df618'
            start: '2025-01-06'
          - builder: superx
            addr: '0x4ecd58def11dc3cadf7deb09f27da69d5475acb3'
            start: '2025-04-16'
          - builder: walletv
            addr: '0x68c68ba58f50bdbe5c4a6faf0186b140eab2b764'
            start: '2025-06-12'
          - builder: basedapp
            addr: '0x1924b8561eef20e70ede628a296175d358be80e5'
            start: '2025-07-09'
          - builder: supercexy
            addr: '0x0000000bfbf4c62c43c2e71ef0093f382bf7a7b4'
            start: '2025-07-13'
          - builder: gtr_trade
            addr: '0x5EF4DeeB76F87d979D0Ddc8c51f5b4F65d1c972A'
            start: '2025-06-16'
          - builder: lootbase
            addr: '0x3e0ef9ad4096c30acefbf7a996f4c19edd071286'
            start: '2025-02-06'
          - builder: dexari
            addr: '0x7975cafdff839ed5047244ed3a0dd82a89866081'
            start: '2025-01-30'
          - builder: liquid8
            addr: '0x7151a036313eee8aa9bc45d0969ca0e1637aad3c'
            start: '2025-03-21'
          - builder: topdog
            addr: '0xaef63e8441987a5e9bf1d37ebb61d8855f405a98'
            start: '2025-04-14'
          - builder: pear_protocol
            addr: '0xA47D4d99191db54A4829cdf3de2417E527c3b042'
            start: '2025-03-24'
          - builder: mass
            addr: '0xf944069B489F1ebfF4C3C6a6014d58cBEf7C7009'
            start: '2025-06-23'
          # …add one block per builder…

    name: Fetch ${{ matrix.builder }}
    steps:
      - uses: actions/checkout@v3

      - name: Purge only raw date JSONs
        run: rm -f data/${{ matrix.builder }}/[0-9]*.json

      - name: Ensure meta files exist
        run: |
          mkdir -p data/${{ matrix.builder }}
          echo '[]' > data/${{ matrix.builder }}/failed_dates.json
          echo '[]' > data/${{ matrix.builder }}/daily_summary.json
          echo '[]' > data/${{ matrix.builder }}/user_data.json

      - name: Fetch & build for ${{ matrix.builder }}
        run: |
          set -e
          NAME=${{ matrix.builder }}
          ADDR="${{ matrix.addr }}"
          ADDR=${ADDR,,}   # lowercase for API
          START_DATE=${{ matrix.start }}
          YEST=$(date -d "yesterday" +%Y-%m-%d)
          FAIL="data/$NAME/failed_dates.json"
          current="$START_DATE"

          # 1) Download daily JSONs (skip if exists)
          while [ "$(date -d "$current" +%Y-%m-%d)" != "$(date -d "$YEST + 1 day" +%Y-%m-%d)" ]; do
            D=$(date -d "$current" +%Y%m%d)
            OUT="data/$NAME/$D.json"

            if [ -f "$OUT" ]; then
              echo "⏭ Skipping $NAME/$D (already exists)"
            else
              RAW=$(curl -s "https://www.flowscan.xyz/api/builder-fills?builderAddress=$ADDR&date=$D")
              if echo "$RAW" | jq -e 'has("error")' >/dev/null; then
                echo "❌ API error for $NAME/$D"
                rm -f "$OUT"
                jq --arg d "$D" 'if index($d)==null then . + [$d] else . end' "$FAIL" > tmp && mv tmp "$FAIL"
              else
                echo "$RAW" > "$OUT"
                jq --arg d "$D" 'map(select(. != $d))' "$FAIL" > tmp && mv tmp "$FAIL"
              fi
            fi

            current=$(date -d "$current + 1 day" +%Y-%m-%d)
          done

          # 2) daily_summary.json
          if ls data/$NAME/[0-9]*.json 1> /dev/null 2>&1; then
            jq -n '[ inputs
              | { date: (input_filename | capture(".*/(?<d>[0-9]{8})\\.json$").d),
                  revenue: .revenue,
                  volume:  .volume,
                  tradecount: .count,
                  uniqueusers: .uniqueUsers }
            ]' data/$NAME/[0-9]*.json > data/$NAME/daily_summary.json
          else
            echo '[]' > data/$NAME/daily_summary.json
          fi

          # 3) user_data.json with active_days
          if ls data/$NAME/[0-9]*.json 1> /dev/null 2>&1; then
            TMP="data/$NAME/_all.json"; echo '[]' > "$TMP"
            for f in data/$NAME/[0-9]*.json; do
              dt=${f##*/}; dt=${dt%.json}
              jq --arg date "$dt" '[ .userAggregations[] | . + {date:$date} ]' "$f" > tmp1
              jq -s '.[0] + .[1]' "$TMP" tmp1 > tmp2 && mv tmp2 "$TMP"
            done
            jq '[.[]] | group_by(.user) | map({
                 user_address:         .[0].user,
                 total_builder_fee_usd: (map(.builder_fee)|add),
                 total_volume:         (map(.total_volume)|add),
                 total_trades:         (map(.count)|add),
                 active_days:          (map(select(.count>0)|.date)|unique|length)
               })' "$TMP" > data/$NAME/user_data.json
            rm tmp1 "$TMP"
          else
            echo '[]' > data/$NAME/user_data.json
          fi

          # 4) split if >3 MB
          SIZE=$(stat -c%s data/$NAME/user_data.json)
          if [ "$SIZE" -gt $((3*1024*1024)) ]; then
            TOTAL=$(jq length data/$NAME/user_data.json)
            CHUNK=5000; CNT=1
            while [ $(( (CNT-1)*CHUNK )) -lt $TOTAL ]; do
              S=$(( (CNT-1)*CHUNK )) ; E=$((S+CHUNK))
              IDX=$(printf "%04d" $CNT)
              jq ".[$S:$E]" data/$NAME/user_data.json > data/$NAME/user_data_$IDX.json
              CNT=$((CNT+1))
            done
            rm data/$NAME/user_data.json
          fi

      - name: Commit ${{ matrix.builder }} data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git stash push --include-untracked --quiet || true
          git pull --rebase origin main
          git stash pop --quiet || true
          git add data/${{ matrix.builder }}
          git diff --quiet --cached || \
            (git commit -m "Update ${{ matrix.builder }} for $(date -d 'yesterday' +%Y%m%d)" && git push)
