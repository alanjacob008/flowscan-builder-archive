permissions:
  contents: write

name: Fetch FlowScan builder‑fills archive

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # daily at midnight UTC

jobs:
  fetch:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - builder: pvp_dot_trade
            addr: '0x0cbf655b0d22ae71fba3a674b0e1c0c7e7f975af'
            start: '2024-10-27'
          - builder: liquid_perps
            addr: '0x6d4e7f472e6a491b98cbeed327417e310ae8ce48'
            start: '2025-06-10'
          - builder: pocket_pro
            addr: '0x7151A036313EEe8Aa9Bc45d0969ca0E1637AAd3C'
            start: '2025-03-22'
          - builder: phantom
            addr: '0xb84168cf3be63c6b8dad05ff5d755e97432ff80b'
            start: '2025-06-12'
          - builder: okto
            addr: '0x05984fd37db96dc2a11a09519a8def556e80590b'
            start: '2024-11-04'
          - builder: axiom
            addr: '0x1cc34f6af34653c515b47a83e1de70ba9b0cda1f'
            start: '2025-01-20'
          - builder: insilico
            addr: '0x2868fc0d9786a740b491577a43502259efa78a39'
            start: '2024-11-24'
          - builder: kinto
            addr: '0xc1f4d15c16a1f3555e0a5f7aefd1e17ad4aaf40b'
            start: '2024-12-25'
          - builder: dextrabot
            addr: '0x49ae63056b3a0be0b166813ee687309ab653c07c'
            start: '2025-02-16'
          - builder: hyperdash
            addr: '0xe966a12bf7b93838096e4519a684519ab22df618'
            start: '2025-01-06'
          - builder: superx
            addr: '0x4ecd58def11dc3cadf7deb09f27da69d5475acb3'
            start: '2025-04-16'
          - builder: walletv
            addr: '0x68c68ba58f50bdbe5c4a6faf0186b140eab2b764'
            start: '2025-06-08'
          - builder: basedapp
            addr: '0x1924b8561eef20e70ede628a296175d358be80e5'
            start: '2025-07-09'
          - builder: supercexy
            addr: '0x0000000bfbf4c62c43c2e71ef0093f382bf7a7b4'
            start: '2025-07-12'
          - builder: gtr_trade
            addr: '0x5EF4DeeB76F87d979D0Ddc8c51f5b4F65d1c972A'
            start: '2025-06-16'
          - builder: lootbase
            addr: '0x3e0ef9ad4096c30acefbf7a996f4c19edd071286'
            start: '2025-02-06'
          - builder: dexari
            addr: '0x7975cafdff839ed5047244ed3a0dd82a89866081'
            start: '2025-01-30'
          - builder: topdog
            addr: '0xaef63e8441987a5e9bf1d37ebb61d8855f405a98'
            start: '2025-04-14'
          - builder: pear_protocol
            addr: '0xA47D4d99191db54A4829cdf3de2417E527c3b042'
            start: '2025-03-24'
          - builder: mass
            addr: '0xf944069B489F1ebfF4C3C6a6014d58cBEf7C7009'
            start: '2025-06-23'
          # …add one block per builder…

        run: |
            set -e
            NAME=${{ matrix.builder }}
            ADDR="${{ matrix.addr }}"
            ADDR=${ADDR,,}
            START_DATE=${{ matrix.start }}
            YEST=$(date -d "yesterday" +%Y-%m-%d)
          
            # Paths
            DIR="data/$NAME"
            FAIL="$DIR/failed_dates.json"
            STORED="$DIR/stored_dates.json"
            TMP_ALL="$DIR/_all.json"
          
            # Ensure all required files exist
            mkdir -p "$DIR"
            [[ -f "$FAIL" ]] || echo '[]' > "$FAIL"
            [[ -f "$STORED" ]] || echo '[]' > "$STORED"
          
            echo '[]' > "$TMP_ALL"
          
            ##############################
            # 1. Retry Failed Dates + New Dates
            ##############################
          
            # Collect list of dates to fetch
            FETCH_DATES=()
          
            # Add failed dates to retry
            for d in $(jq -r '.[]' "$FAIL"); do
              FETCH_DATES+=("$d")
            done
          
            # Add new dates since last stored
            current="$START_DATE"
            while [ "$(date -d "$current" +%Y-%m-%d)" != "$(date -d "$YEST + 1 day" +%Y-%m-%d)" ]; do
              D=$(date -d "$current" +%Y%m%d)
              if ! jq -e --arg d "$D" 'index($d)' "$STORED" >/dev/null; then
                FETCH_DATES+=("$D")
              fi
              current=$(date -d "$current + 1 day" +%Y-%m-%d)
            done
          
            echo "🗓️ Fetching ${#FETCH_DATES[@]} date(s) for $NAME"
          
            ##############################
            # 2. Fetch Data Per Date
            ##############################
            for D in "${FETCH_DATES[@]}"; do
              OUT="$DIR/$D.json"
              echo "🌐 Fetching $D..."
          
              STATUS=$(curl -sS -w '%{http_code}' -o tmp_raw.json \
                -H "Accept: application/json, text/plain, */*" \
                -H "Accept-Language: en-US,en;q=0.9" \
                -H "Cache-Control: no-cache" \
                -H "Pragma: no-cache" \
                -H "Referer: https://www.flowscan.xyz/builders?builder=$NAME" \
                -H "Origin: https://www.flowscan.xyz" \
                -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36" \
                "https://www.flowscan.xyz/api/builder-fills?builderAddress=$ADDR&date=$D")
          
              echo "↩️ Status $STATUS"
          
              if [ "$STATUS" = "200" ] && ! jq -e 'has("error")' tmp_raw.json >/dev/null; then
                mv tmp_raw.json "$OUT"
                echo "✅ Success: $D"
                # Update stored dates
                jq --arg d "$D" 'if index($d)==null then . + [$d] else . end' "$STORED" > tmp && mv tmp "$STORED"
                jq --arg d "$D" 'map(select(. != $d))' "$FAIL" > tmp && mv tmp "$FAIL"
              else
                echo "❌ Failed: $D"
                rm -f tmp_raw.json "$OUT"
                jq --arg d "$D" 'if index($d)==null then . + [$d] else . end' "$FAIL" > tmp && mv tmp "$FAIL"
              fi
          
              sleep 1
            done
          
            ##############################
            # 3. Build daily_summary.json
            ##############################
            if ls $DIR/[0-9]*.json 1> /dev/null 2>&1; then
              jq -n '[ inputs
                | { date: (input_filename | capture(".*/(?<d>[0-9]{8})\\.json$").d),
                    revenue: .revenue,
                    volume:  .volume,
                    tradecount: .count,
                    users: .uniqueUsers }
              ]' $DIR/[0-9]*.json > $DIR/daily_summary.json
            else
              echo '[]' > $DIR/daily_summary.json
            fi
          
            ##############################
            # 4. Build user_data_0001+.json (chunked)
            ##############################
            if ls $DIR/[0-9]*.json 1> /dev/null 2>&1; then
              TMP="$DIR/_all.json"
              echo '[]' > "$TMP"
              for f in $DIR/[0-9]*.json; do
                dt=${f##*/}; dt=${dt%.json}
                jq --arg date "$dt" '[ .userAggregations[] | . + {date:$date} ]' "$f" > tmp1
                jq -s '.[0] + .[1]' "$TMP" tmp1 > tmp2 && mv tmp2 "$TMP"
              done
          
              # Cleanup old chunks
              rm -f $DIR/user_data_*.json
          
              jq '[.[]] | group_by(.user) | map({
                   user_address: .[0].user,
                   total_builder_fee_usd: (map(.builder_fee)|add),
                   total_volume: (map(.total_volume)|add),
                   total_trades: (map(.count)|add),
                   active_days: (map(select(.count>0)|.date)|unique|length)
                 })' "$TMP" > tmp_users.json
          
              # Always chunk user data
              TOTAL=$(jq length tmp_users.json)
              CHUNK=5000; CNT=1
              while [ $(( (CNT-1)*CHUNK )) -lt $TOTAL ]; do
                S=$(( (CNT-1)*CHUNK )) ; E=$((S+CHUNK))
                IDX=$(printf "%04d" $CNT)
                jq ".[$S:$E]" tmp_users.json > "$DIR/user_data_$IDX.json"
                CNT=$((CNT+1))
              done
              rm tmp1 tmp_users.json "$TMP"
            fi
          
            ##############################
            # 5. Inject unique_users into daily_summary.json
            ##############################
            if ls $DIR/user_data_*.json 1> /dev/null 2>&1; then
              TOTAL_USERS=$(jq -s '[.[][] | .user_address] | unique | length' $DIR/user_data_*.json)
              jq --argjson uu "$TOTAL_USERS" 'map(. + {unique_users: $uu})' $DIR/daily_summary.json > tmp && mv tmp $DIR/daily_summary.json
            fi
          
            ##############################
            # 6. Git Commit (if changes)
            ##############################
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git stash push --include-untracked --quiet || true
            git pull --rebase origin main
            git stash pop --quiet || true
            git add $DIR
            git diff --quiet --cached || \
              (git commit -m "Update $NAME for $(date -d 'yesterday' +%Y%m%d)" && git push)
